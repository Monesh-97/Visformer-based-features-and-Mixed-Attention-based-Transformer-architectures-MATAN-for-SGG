# Visformer-based-features-and-Mixed-Attention-based-Transformer-architectures-MATAN-for-Scene Graph Generation


Mixed Attention-based Transformer Network (MATAN), a novel approach for scene graph generation that integrates visformer-based feature extraction with a combination of self-attention, cross-attention, and positional encoding within a transformer framework. Unlike existing methods that struggle to represent complex object relationships in diverse visual contexts, MATAN employs Visformer’s multiscale feature extraction to generate rich visual representations. These features are then passed through a set of transformer modules tailored for relationship modelling. The method is evaluated on the Visual Relationship Detection (VRD) dataset, where it demonstrates superior performance in terms of accuracy and relational understanding compared to baseline models.
•	Methodological Innovation: Combines Visformer’s multiscale visual features with multiple attention mechanisms (self-, cross-, positional) in a transformer-based pipeline. 
•	Method advantages: It achieved superior performance in relationship modelling with 94.067% accuracy, 95.654% TPR, and 93.126% F-measure on the VRD dataset.
•	Method applications: Enhances scene understanding for visual reasoning, image captioning, and improves performance in downstream vision language applications.
